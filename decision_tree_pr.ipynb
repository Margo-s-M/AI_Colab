{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Margo-s-M/AI_Colab/blob/decision_tree/decision_tree_pr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Decision_Tree_Header](https://raw.githubusercontent.com/satishgunjal/images/master/Decision_Tree_Header.png)\n",
        "\n",
        "Алгоритм дерева рішень належить до сімейства алгоритмів навчання з учителем. На відміну від інших алгоритмів навчання з учителем, дерево рішень може використовуватися для вирішення задач регресії та класифікації.\n",
        "\n",
        "Мета дерева рішень полягає в тому, щоб створити навчальну модель, яка може прогнозувати клас (один або декілька) або значення, навчаючись простих правил прийняття рішень на основі навчальних даних.\n",
        "\n",
        "Дерева рішень утворюють структуру, схожу на блок-схему, тому їх дуже легко інтерпретувати та розуміти. Це один з небагатьох алгоритмів машинного навчання, де дуже легко візуалізувати та проаналізувати внутрішню роботу алгоритму.\n",
        "\n",
        "Так само, як і блок-схема, дерево рішень містить різні типи вузлів і гілок. Кожен вузол рішення представляє тест за ознакою, і на основі результату тесту він або утворює іншу гілку, або кінцевий вузол. Кожна гілка представляє правило прийняття рішення, а кінцевий вузол - кінцевий результат.\n",
        "\n",
        "![дерево рішень](https://raw.githubusercontent.com/satishgunjal/images/master/Decision_Tree.png)\n",
        "\n",
        "\n",
        "Типи дерев рішень\n",
        "Дерева рішень бувають двох основних типів:\n",
        "\n",
        "* **Дерева рішень класифікації**: У цьому типі дерев рішень цільова змінна є категоріальною. Наприклад, класифікація електронних листів як спаму або не спаму.\n",
        "* **Дерева регресії**: У цьому типі дерев рішень цільова змінна є безперервною. Наприклад, прогнозування цін на будинки на основі їх характеристик."
      ],
      "metadata": {
        "id": "ZXewvWh2xmd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Внутрішня робота дерева рішень\n",
        "\n",
        "Дерево рішень на кореневому вузлі обирає атрибут для розділення даних на дві основні категорії. Таким чином, наприкінці кореневого вузла ми маємо два правила рішення та два піддерева.\n",
        "\n",
        "Дані знову будуть розділені на дві категорії в кожному піддереві. Цей процес триватиме, доки всі навчальні приклади не будуть згруповані разом.\n",
        "\n",
        "Отже, наприкінці дерева рішень ми отримуємо кінцевий вузол. Він представляє клас або безперервне значення, яке ми намагаємося передбачити.\n",
        "\n",
        "## Критерії розділення даних\n",
        "\n",
        "Метою дерева рішень є розділення даних таким чином, щоб наприкінці ми отримали різні групи даних, які мають більшу схожість і меншу випадковість/нечистоту. Для досягнення цього кожен розділ у дереві рішень повинен зменшувати випадковість. Дерево рішень використовує критерії вибору \"ентропія\" або \"коефіцієнт Джіні\" для розділення даних.\n",
        "\n",
        "Примітка: ми використовуватимемо бібліотеку scikit-learn для тестування класифікації та регресії. \"Ентропія\" або \"коефіцієнт Джіні\" є критеріями вибору для класифікатора, тоді як \"mse\" (середня квадратична похибка), \"friedman_mse\" та \"mae\" (середня абсолютна похибка) є критеріями вибору для регресора.\n",
        "\n",
        "## Ентропія\n",
        "\n",
        "Для того, щоб знайти найкращий атрибут, який зменшить випадковість після розділу, ми можемо порівняти випадковість до та після розділу для кожного атрибута. Зрештою, ми обираємо атрибут, який забезпечить найбільше зниження випадковості. Формально випадковість у даних називається \"ентропією\", а різниця між \"ентропією\" до та після розділу називається \"коефіцієнтом інформаційного приросту\". Оскільки в дереві рішень може бути кілька гілок, формулу коефіцієнта інформаційного приросту можна записати так:\n",
        "\n",
        "![entropy_formula](https://raw.githubusercontent.com/satishgunjal/images/master/entropy_formula.png)\n",
        "\n",
        "```\n",
        "Коефіцієнт інформаційного приросту = Ентропія(Батьківський вузол) - (Середня ентропія(Дочірні вузли))\n",
        "```\n",
        "\n",
        "Таким чином, у випадку з \"ентропією\" дерево рішень розділить дані за допомогою атрибута, який забезпечує найбільший коефіцієнт інформаційного приросту.\n",
        "\n",
        "## Коефіцієнт Джіні\n",
        "\n",
        "У випадку нечистоти за Джіні, ми обираємо випадкову точку даних у нашому наборі даних. Потім випадково класифікуємо її відповідно до розподілу класів у наборі даних. Тому дуже важливо знати точність цієї випадкової класифікації. Нечистота за Джіні дає нам ймовірність неправильної класифікації. Ми визначимо якість розділу, зважуючи нечистоту кожної гілки кількістю елементів, які вона містить. Отримане значення називається \"коефіцієнтом приросту Джіні\" або \"коефіцієнтом Джіні\". Саме це використовується для вибору найкращого розділу в дереві рішень. Чим більший коефіцієнт приросту Джіні, тим краще розділення.\n",
        "\n",
        "![gini_formula](https://raw.githubusercontent.com/satishgunjal/images/master/gini_formula.png)\n",
        "\n",
        "Таким чином, у випадку з \"коефіцієнтом Джіні\" дерево рішень розділить дані за допомогою атрибута, який забезпечує найбільший коефіцієнт приросту Джіні.\n",
        "\n",
        "## Що ж нам використовувати?\n",
        "\n",
        "Нечистота за Джіні обчислюється швидше, оскільки не потребує обчислення логарифмічних функцій, хоча насправді жодна з метрик не призводить до більш точного дерева, ніж інша."
      ],
      "metadata": {
        "id": "n6wFxvrBom9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Переваги дерева рішень\n",
        "\n",
        "Дерева рішень є популярним алгоритмом машинного навчання завдяки низці переваг:\n",
        "\n",
        "* **Легкість розуміння та інтерпретації.** Дерева можна візуалізувати, що дозволяє легко зрозуміти логіку прийняття ними рішень.\n",
        "* **Мінімальна підготовка даних.** На відміну від інших методів, дерева рішень не потребують складної підготовки даних, такої як нормалізація, створення фіктивних змінних та видалення пустих значень.  Однак, зауважте, що цей модуль не підтримує роботу з відсутніми значеннями.\n",
        "* **Здатність обробляти як числові, так і категоріальні дані.** Дерева рішень можуть працювати з різними типами даних, що робить їх універсальним інструментом.\n",
        "* **Обробка задач з кількома вихідними значеннями.**  Дерева рішень можуть прогнозувати не тільки одне, але й декілька цільових значень одночасно.\n",
        "* **Модель типу \"біла скринька\".** Оскільки логіка дерева рішень легко інтерпретується, ви можете зрозуміти, як воно приходить до своїх прогнозів.\n",
        "* **Можливість перевірки моделі за допомогою статистичних тестів.** Ви можете використовувати статистичні тести для оцінки надійності моделі дерева рішень. Це дозволяє вам зрозуміти, наскільки можна довіряти її прогнозам.\n"
      ],
      "metadata": {
        "id": "XxtWcPnaxmd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Недоліки дерева рішень\n",
        "\n",
        "* **Перенавчання:** Алгоритми дерев рішень можуть створювати надто складні дерева, які погано узагальнюють дані. Це явище називається перенавчанням. Для уникнення цієї проблеми необхідні механізми, такі як обрізка гілок, встановлення мінімальної кількості зразків, необхідних у кінцевому вузлі, або встановлення максимальної глибини дерева.\n",
        "* **Нестабільність:** Дерева рішень можуть бути нестабільними, оскільки незначні зміни в даних можуть призвести до створення абсолютно іншого дерева. Цю проблему можна пом'якшити за допомогою використання дерев рішень в ансамблі.\n",
        "* **Зміщення в бік більшості класів:** Алгоритми дерев рішень створюють дерева із зміщенням, якщо деякі класи переважають інші. Тому перед навчанням за допомогою дерева рішень рекомендується балансувати набір даних.\n"
      ],
      "metadata": {
        "id": "LJqArOBDxmeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn import tree\n",
        "import graphviz"
      ],
      "metadata": {
        "trusted": true,
        "id": "wfv5GonTxmeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дані\n",
        "Ціни на діаманти"
      ],
      "metadata": {
        "id": "NX5GNF2KxmeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module3/data/diamonds2.csv\",\n",
        "                 index_col=0\n",
        "                 )"
      ],
      "metadata": {
        "id": "yn8ospWKFKeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "dNitdALNFONK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "06FJx_8RigJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Побудова моделі"
      ],
      "metadata": {
        "id": "NB6BuXSexmeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Поділ даних"
      ],
      "metadata": {
        "id": "e01-farcJt8H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvxyXPkQFdKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9-U-77kFlcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Створення Pipeline"
      ],
      "metadata": {
        "id": "ZJJNqVJNJwcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "rRVms94DF8rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7evHR4DFoTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Остаточна модель"
      ],
      "metadata": {
        "id": "UZBpEG3iKX8b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNijPkEqF-iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rL7RilOFGGQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метрики"
      ],
      "metadata": {
        "id": "Ff-K9rMdM1bv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lm4F2Sl2M4rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_GHL5dZM-Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Візуалізація дерева\n",
        "За дапомогою функції `tree.export_graphviz` та модулю `graphviz` можна зберегти дерево як зображення блок-схеми"
      ],
      "metadata": {
        "id": "K4lbFboExmeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = tree.export_graphviz(model['tree'], out_file=None,\n",
        "                                feature_names = model['tree'].feature_names_in_) # вказуємо назви стовпчиків\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"diamond tree\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "LwefhV1sxmeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X['carat'], y, label='data')\n",
        "plt.scatter(X['carat'], model.predict(X), c='darkgreen', label='model')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "hOUUKDsDDm7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Важливість ознак"
      ],
      "metadata": {
        "id": "OzIWS2NTLTFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Після тренування дерева, у його атрибуті `feature_importances_` зберігається важливість тої чи іншої ознаки для прогнозування. Назви ознак після обробки можна також отримати з атрибуту `feature_names_in_`"
      ],
      "metadata": {
        "id": "EkNZ2yixLaZY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV6LQc2TLZAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FYORTfGWMKTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Збереження моделі"
      ],
      "metadata": {
        "id": "ulENq7vE6-SR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTLwYdWdOh-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wr-oFC2u7Gqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}